{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Imports**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 85.09%\n",
      "Predicted class for new data (RainTomorrow): No\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder, StandardScaler\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# Example Data Input (Modify this path to your CSV dataset)\n",
    "data = pd.read_csv('data/weatherAUS.csv')\n",
    "\n",
    "# Preprocessing\n",
    "\n",
    "# Drop rows with missing values for simplicity (you can handle this more carefully in real cases)\n",
    "data = data.dropna()\n",
    "\n",
    "# Encode categorical variables using LabelEncoder\n",
    "le = LabelEncoder()\n",
    "categorical_cols = ['Location', 'WindGustDir', 'WindDir9am', 'WindDir3pm', 'RainToday', 'RainTomorrow']\n",
    "for col in categorical_cols:\n",
    "    data[col] = le.fit_transform(data[col])\n",
    "\n",
    "# Select features\n",
    "features = ['MinTemp', 'MaxTemp', 'Rainfall', 'WindGustSpeed', 'WindSpeed9am', 'WindSpeed3pm',\n",
    "            'Humidity9am', 'Humidity3pm', 'Pressure9am', 'Pressure3pm', 'Cloud9am', 'Temp9am', \n",
    "            'Temp3pm', 'RainToday']\n",
    "\n",
    "X = data[features].values\n",
    "y = data['RainTomorrow'].values  # Target variable (1 for rain, 0 for no rain)\n",
    "\n",
    "# Normalize the features\n",
    "scaler = StandardScaler()\n",
    "X = scaler.fit_transform(X)\n",
    "\n",
    "# Train-test split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Initialize the MLPClassifier\n",
    "# passes to the hidden layer and performs \n",
    "mlp = MLPClassifier(hidden_layer_sizes=(10), max_iter=1000, random_state=42)\n",
    "\n",
    "# Train the MLP model\n",
    "mlp.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions on the test set\n",
    "y_pred = mlp.predict(X_test)\n",
    "\n",
    "# Evaluate the model\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(f'Accuracy: {accuracy * 100:.2f}%')\n",
    "\n",
    "# Example of new data\n",
    "# This is based on the structure of your input data, assuming this order of features\n",
    "new_data = np.array([[13.4, 25.9, 0.6, 44, 20, 24, 71, 22, 1007.7, 1007.1, 8, 16.9, 21.8, 0]])  # RainToday is encoded as 0 (No)\n",
    "\n",
    "# Scale the new data using the same scaler used for training\n",
    "new_data_scaled = scaler.transform(new_data)\n",
    "\n",
    "# Predict the class for the new data\n",
    "prediction = mlp.predict(new_data_scaled)\n",
    "print(f'Predicted class for new data (RainTomorrow): {\"Yes\" if prediction[0] == 1 else \"No\"}')\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from numpy import mean\n",
    "from numpy import std\n",
    "from sklearn.datasets import make_classification\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import RepeatedStratifiedKFold\n",
    "from sklearn.linear_model import Perceptron\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error\n",
    "from sklearn.preprocessing import LabelEncoder, StandardScaler\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# define model\n",
    "model = Perceptron(eta0=0.1)\n",
    "\n",
    "# define model\n",
    "model = Perceptron(max_iter=1000)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0: Weights=[ 0.00236597  0.02130895  0.03897949  0.09150198 -0.01522458 -0.03255633\n",
      "  0.00755841  0.07912907  0.0790472  -0.05710425 -0.00738741  0.01364493\n",
      " -0.01440379 -0.00295084  0.04259562], Bias=-0.08\n",
      "Epoch 100: Weights=[ 0.02912528  0.01006401  0.04758877  0.09993481 -0.00480542 -0.03440537\n",
      "  0.0039133   0.07605732  0.06966996 -0.08139703 -0.00554056  0.00740054\n",
      " -0.00162948  0.00213853  0.03194671], Bias=-0.060000000000000005\n",
      "Epoch 200: Weights=[ 0.01317418  0.03950074  0.04449586  0.07359635 -0.01241973 -0.0311307\n",
      " -0.01397989  0.05308444  0.08434512 -0.06233736 -0.01540169  0.00485643\n",
      "  0.00370699 -0.00340477  0.03727116], Bias=-0.07\n",
      "Epoch 300: Weights=[ 0.00465761  0.04320313  0.0373247   0.07893761 -0.02284092 -0.04498104\n",
      "  0.00715424  0.05922302  0.0431839  -0.05316173 -0.00196547  0.02628823\n",
      " -0.00299978 -0.0010795   0.03194671], Bias=-0.060000000000000005\n",
      "Epoch 400: Weights=[ 0.01250477  0.0243824   0.02131503  0.08877827 -0.0224408  -0.02710438\n",
      "  0.01532459  0.11091324  0.06396821 -0.05723049 -0.01355484  0.02883234\n",
      " -0.0112291   0.00855947  0.05072799], Bias=-0.05\n",
      "Epoch 500: Weights=[ 0.01681352  0.0358867   0.05771029  0.08418691 -0.03726931 -0.02500478\n",
      "  0.00175267  0.09140624  0.07140675 -0.0537439  -0.00554056  0.01117808\n",
      " -0.01167831 -0.00093323  0.00784098], Bias=-0.060000000000000005\n",
      "Epoch 600: Weights=[-0.00048527  0.02986141  0.01679656  0.07668791 -0.01562672 -0.01677927\n",
      "  0.01255581  0.09685263  0.06677531 -0.05796464  0.00518469  0.00740054\n",
      " -0.00376105 -0.0061991   0.05605244], Bias=-0.060000000000000005\n",
      "Epoch 700: Weights=[ 0.00200825  0.03760821  0.01679656  0.08418691 -0.01081725 -0.02617986\n",
      " -0.00526938  0.06912555  0.06489378 -0.08154257 -0.00196547  0.02628823\n",
      " -0.0160937   0.0022848   0.03194671], Bias=-0.060000000000000005\n",
      "Epoch 800: Weights=[-0.00287785  0.03663155  0.02767419  0.09834304 -0.01241973 -0.02643041\n",
      "  0.00114452  0.0842774   0.0642273  -0.04734645 -0.00825152  0.0124115\n",
      " -0.02248085  0.00361638  0.03727116], Bias=-0.07\n",
      "Epoch 900: Weights=[ 0.02059984  0.03221186  0.02814519  0.09300178 -0.01642694 -0.04078184\n",
      " -0.01080694  0.07863394  0.07571835 -0.06772887  0.00333784  0.01742246\n",
      " -0.00435497 -0.0234292   0.01848989], Bias=-0.08\n",
      "Accuracy: 80.81%\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.8081354129741226"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "# Load dataset\n",
    "data = pd.read_csv('data/weatherAUS.csv')\n",
    "\n",
    "# Preprocessing\n",
    "\n",
    "# Drop rows with missing values for simplicity\n",
    "data = data.dropna()\n",
    "\n",
    "# Convert categorical columns to numeric using LabelEncoder\n",
    "le = LabelEncoder()\n",
    "\n",
    "categorical_cols = ['Location', 'WindGustDir', 'WindDir9am', 'WindDir3pm', 'RainToday', 'RainTomorrow']\n",
    "for col in categorical_cols:\n",
    "    data[col] = le.fit_transform(data[col])\n",
    "\n",
    "# Feature Selection\n",
    "features = ['MinTemp', 'MaxTemp', 'Rainfall', 'WindGustSpeed', 'WindSpeed9am', 'WindSpeed3pm',\n",
    "            'Humidity9am', 'Humidity3pm', 'Pressure9am', 'Pressure3pm', 'Cloud9am', 'Cloud3pm', \n",
    "            'Temp9am', 'Temp3pm', 'RainToday']\n",
    "\n",
    "X = data[features].values\n",
    "y = data['RainTomorrow'].values  # This is the target (1 for rain, 0 for no rain)\n",
    "\n",
    "# Normalize the features\n",
    "scaler = StandardScaler()\n",
    "X = scaler.fit_transform(X)\n",
    "\n",
    "# Train-test split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Implement Perceptron from scratch\n",
    "\n",
    "class Perceptron:\n",
    "    def __init__(self, input_dim, learning_rate=0.01, epochs=1000):\n",
    "        self.learning_rate = learning_rate\n",
    "        self.epochs = epochs\n",
    "        self.weights = np.zeros(input_dim)\n",
    "        self.bias = 0\n",
    "\n",
    "    def activation(self, x):\n",
    "        # Step function\n",
    "        return 1 if x >= 0 else 0\n",
    "\n",
    "    def predict(self, X):\n",
    "        linear_output = np.dot(X, self.weights) + self.bias\n",
    "        return self.activation(linear_output)\n",
    "\n",
    "    def train(self, X_train, y_train):\n",
    "        for epoch in range(self.epochs):\n",
    "            for i in range(X_train.shape[0]):\n",
    "                prediction = self.predict(X_train[i])\n",
    "                error = y_train[i] - prediction\n",
    "\n",
    "                # Update the weights and bias\n",
    "                self.weights += self.learning_rate * error * X_train[i]\n",
    "                self.bias += self.learning_rate * error\n",
    "\n",
    "            if epoch % 100 == 0:\n",
    "                print(f\"Epoch {epoch}: Weights={self.weights}, Bias={self.bias}\")\n",
    "\n",
    "    def evaluate(self, X_test, y_test):\n",
    "        correct = 0\n",
    "        for i in range(X_test.shape[0]):\n",
    "            prediction = self.predict(X_test[i])\n",
    "            if prediction == y_test[i]:\n",
    "                correct += 1\n",
    "        accuracy = correct / len(y_test)\n",
    "        print(f\"Accuracy: {accuracy * 100:.2f}%\")\n",
    "        return accuracy\n",
    "\n",
    "# Initialize the perceptron\n",
    "input_dim = X_train.shape[1]\n",
    "perceptron = Perceptron(input_dim=input_dim, learning_rate=0.01, epochs=1000)\n",
    "\n",
    "# Train the perceptron\n",
    "perceptron.train(X_train, y_train)\n",
    "\n",
    "# Evaluate the perceptron on the test set\n",
    "perceptron.evaluate(X_test, y_test)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
